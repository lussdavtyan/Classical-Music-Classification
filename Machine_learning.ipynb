{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import music21\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import average_precision_score, f1_score, confusion_matrix, fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataset using the pickle files obtained in feature_extraction.ipynb. This is done in order\n",
    "# not to run the part extracting the features every time. \n",
    "\n",
    "X_train = pd.read_pickle(r'data/X_train.pickle')\n",
    "X_validation = pd.read_pickle(r'data/X_validation.pickle')\n",
    "X_test = pd.read_pickle(r'data/X_test.pickle')\n",
    "y_train = pd.read_pickle(r'data/y_train.pickle')\n",
    "y_validation = pd.read_pickle(r'data/y_validation.pickle')\n",
    "y_test = pd.read_pickle(r'data/y_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute the validation set, that was present initially, between train and test sets\n",
    "\n",
    "X_test = np.concatenate((X_test, X_validation[:int(len(X_validation) / 2)]))\n",
    "y_test = np.concatenate((y_test, y_validation[:int(len(X_validation) / 2)]))\n",
    "X_train = np.concatenate((X_train, X_validation[int((len(X_validation) / 2) + 1):]))\n",
    "y_train = np.concatenate((y_train, y_validation[int((len(X_validation) / 2) + 1):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove constant features\n",
    "\n",
    "vt = VarianceThreshold(threshold=0)\n",
    "vt.fit(X_train)\n",
    "X_train = vt.transform(X_train)\n",
    "X_test = vt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 122)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove highly correlated features\n",
    "# Based on the code at https://www.dezyre.com/recipes/drop-out-highly-correlated-features-in-python\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "correlation_matrix = df.corr()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column].abs() > 0.9)]\n",
    "df1 = df.drop(df.columns[to_drop], axis=1)\n",
    "X_train = df1.to_numpy()\n",
    "\n",
    "df = pd.DataFrame(X_test)\n",
    "df = df.drop(df.columns[to_drop], axis=1)\n",
    "\n",
    "X_test = df.to_numpy()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1035, 125)\n",
      "(1035,)\n",
      "(246, 125)\n",
      "(246,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the dataset, since it is necessary for some of the models used\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the ordinal classification index, given the true and predicted labels\n",
    "# Based on this source (https://www.researchgate.net/publication/220360337_Measuring_the_Performance_of_Ordinal_Classification)\n",
    "\n",
    "def ordinal_classification_index(y, y_pred):\n",
    "    cMatrix = confusion_matrix(y, y_pred)\n",
    "    k = len(cMatrix)\n",
    "    n = np.sum(cMatrix)\n",
    "    gamma = 1\n",
    "    beta = 0.75 / (n * (k - 1)**gamma)\n",
    "    helperM2 = np.zeros((k, k))\n",
    "    \n",
    "    for r in range(0, k):\n",
    "        for c in range(0, k):\n",
    "            helperM2[r, c] = cMatrix[r, c] * ((np.abs(r - c))**gamma)\n",
    "            \n",
    "    total_dispersion = (np.sum(helperM2)**(1 / gamma))\n",
    "    helperM1 = cMatrix / (total_dispersion + n)\n",
    "    err_matrix = np.zeros((k, k))\n",
    "    err_matrix[0, 0] = 1 - helperM1[0, 0] + beta * helperM2[0, 0]\n",
    "    for r in range(1, k):\n",
    "        c = 0\n",
    "        err_matrix[r, c] = err_matrix[r - 1, c] - helperM1[r, c] + beta * helperM2[r, c]\n",
    "\n",
    "    for c in range(1, k):\n",
    "        r = 0\n",
    "        err_matrix[r, c] = err_matrix[r, c - 1] - helperM1[r, c] + beta * helperM2[r, c]\n",
    "    \n",
    "    for c in range(1, k):\n",
    "        for r in range(1, k):\n",
    "            cost_up = err_matrix[r - 1, c]\n",
    "            cost_left = err_matrix[r, c - 1]\n",
    "            left_top_cost = err_matrix[r - 1, c - 1]\n",
    "            aux = np.min([cost_up, cost_left, left_top_cost])\n",
    "            err_matrix[r, c] = aux - helperM1[r, c] + beta * helperM2[r, c]\n",
    "       \n",
    "    oc = err_matrix[-1, -1]\n",
    "\n",
    "    return oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "oci = make_scorer(ordinal_classification_index, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = {\"n_neighbors\": range(1, 300)}\n",
    "model = KNeighborsClassifier()\n",
    "gs = GridSearchCV(model, param_grid=grid, verbose=0, scoring=oci)\n",
    "gs.fit(X_train, y_train)\n",
    "knn_best_params = gs.best_params_\n",
    "knn = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=39)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [2, 4, 6],\n",
    "    'max_depth': [10, 30, 50],\n",
    "    'max_features': [2, 3],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'random_state': range(0, 10)\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=grid, cv=3)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "rf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"C\": [0.001, 0.01, 1, 10, 100, 1000], \n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'kernel':['linear', 'rbf','poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "md = SVC()\n",
    "gs = GridSearchCV(md, param_grid=grid,verbose=0, scoring=oci)\n",
    "gs.fit(X_train, y_train)\n",
    "svc_best_params = gs.best_params_\n",
    "svc = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.01)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K Nearest Neighbors\": knn,\n",
    "    \"LDA\": lda,\n",
    "    \"QDA\": qda,\n",
    "    \"GaussianNB\": nb,\n",
    "    \"SVC\": svc,\n",
    "    \"Random Forest\": rf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.71        30\n",
      "           1       0.50      0.45      0.47        38\n",
      "           2       0.80      0.91      0.85       164\n",
      "           3       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.76       246\n",
      "   macro avg       0.52      0.51      0.51       246\n",
      "weighted avg       0.71      0.76      0.73       246\n",
      "\n",
      "\n",
      "OCI: 0.3230736367873233 \n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.63      0.51        30\n",
      "           1       0.44      0.53      0.48        38\n",
      "           2       0.79      0.65      0.71       164\n",
      "           3       0.10      0.14      0.11        14\n",
      "\n",
      "    accuracy                           0.60       246\n",
      "   macro avg       0.44      0.49      0.46       246\n",
      "weighted avg       0.65      0.60      0.62       246\n",
      "\n",
      "\n",
      "OCI: 0.5357204635876146 \n",
      "\n",
      "\n",
      "\n",
      "QDA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        30\n",
      "           1       1.00      0.03      0.05        38\n",
      "           2       0.67      1.00      0.80       164\n",
      "           3       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.67       246\n",
      "   macro avg       0.67      0.26      0.23       246\n",
      "weighted avg       0.72      0.67      0.55       246\n",
      "\n",
      "\n",
      "OCI: 0.42063151265315474 \n",
      "\n",
      "\n",
      "\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.30      0.39        30\n",
      "           1       0.39      0.95      0.55        38\n",
      "           2       0.91      0.59      0.71       164\n",
      "           3       0.12      0.29      0.17        14\n",
      "\n",
      "    accuracy                           0.59       246\n",
      "   macro avg       0.50      0.53      0.46       246\n",
      "weighted avg       0.75      0.59      0.62       246\n",
      "\n",
      "\n",
      "OCI: 0.4402954311233254 \n",
      "\n",
      "\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75        30\n",
      "           1       0.62      0.34      0.44        38\n",
      "           2       0.82      0.94      0.88       164\n",
      "           3       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.78       246\n",
      "   macro avg       0.53      0.53      0.52       246\n",
      "weighted avg       0.72      0.78      0.74       246\n",
      "\n",
      "\n",
      "OCI: 0.29686887302956644 \n",
      "\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        30\n",
      "           1       0.72      0.74      0.73        38\n",
      "           2       0.87      0.93      0.90       164\n",
      "           3       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.83       246\n",
      "   macro avg       0.58      0.62      0.60       246\n",
      "weighted avg       0.78      0.83      0.80       246\n",
      "\n",
      "\n",
      "OCI: 0.24731050340806443 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/SFLPRO/lusine.davtyan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get the classification reports\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print()\n",
    "    print(name)\n",
    "    print(classification_report(y_pred=pred, y_true=y_test))\n",
    "    print()\n",
    "    print(\"OCI:\", ordinal_classification_index(y_test, pred), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>OCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.247311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.296869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>0.323074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.420632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.440295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.535720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name       OCI\n",
       "5        Random Forest  0.247311\n",
       "4                  SVC  0.296869\n",
       "0  K Nearest Neighbors  0.323074\n",
       "2                  QDA  0.420632\n",
       "3           GaussianNB  0.440295\n",
       "1                  LDA  0.535720"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the models according to the OCI\n",
    "\n",
    "table = pd.DataFrame(columns=[\"name\", \"OCI\"])\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    table = table.append({\"name\": name,\n",
    "                          \"OCI\": ordinal_classification_index(model.predict(X_test), y_test)},\n",
    "                           ignore_index=True\n",
    "                        )\n",
    "\n",
    "table.sort_values(\"OCI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
